\chapter{State of the Art}
\label{chapter:stateoftheart}

\section{Background}
\label{sec:background}

The internet is offering a voice to millions of people that have access to it.
Creating content which is accessible by everyone in the network is possible with little or no barriers. Anyone can report on events, share their thoughts and ideas and because there are no limits to this process the results are massive amounts of information.
\newline
Facebook\footnote{www.facebook.com} and Twitter\footnote{www.twitter.com} are two examples of Internet platforms that have made it increasingly easier for people to generate content in a multitude of different formats: from text and pictures to rich media such as audio and video.
\newline
People send on average 50 million tweets with a peek record of 6939 TPS record. Facebook has even bigger numbers, in an average of 20 minutes, 1 million links are shared, 10 million comments are posted and 1,6 million wall posts are made\footnote{http://highscalability.com/blog/2010/12/31/facebook-in-20-minutes-27m-photos-102m-comments-46m-messages.html}. \todo{add number of users for each platform}. These are just two examples of popular social media websites and the rate at which content is being generated.
\newline
At the same time Facebook offers no way for a user to search through those comments and posts. 
\newline
People communicate in short gists with the help of special annotations made possible on the platform. Mentions are a way of including another Twitter user into the conversation, they are formed by prepending the character "@" to the string that represents the user. Hashtags are a method of creating channels of communication, they are a way to distill the idea or felling of your tweet to a single word, and by doing so you ensure the inclusion of your message to a certain ongoing conversation. Hashtags are created by prepending the character "\#" in front of words. Users can also reply to tweets, their message is grouped with the one they are replying to and context is preserved this way.
Due to its short message format of 140 characters per message, Twitter has become a popular micro blogging platform for reporting on news and events as they occur.
As a user you can always view the 10 most popular hashtags in different regions around the world or worldwide and participate in the conversation. You can also search for a certain query and messages that match gets returned either if it contains the string as a hashtag or in the message body.
\newline
The massive amount of information being generated especially on popular topics make it difficult to keep track of conversations as they happen. Unlike Facebook where the people you interact with are mostly people you know and that number can be within reasonable limits, on Twitter there are no barriers in communication and you have access to all the messages produced by every user of the platform. Even though hashtags help filter conversations they are too inclusive, there are no constraints over how to use them or how many to use so messages are included to any conversation as long as they have the hashtag.
\newline
There are a number of services that use Twitter data and attempt to solve some of these problems. We will be presenting some of them in the following section.

\section{Existing Solutions}
\label{sec:ES}

\subsection{Analytics}
\label{sub-sec:analytics}

There are a number of analytics services that provide information regarding Twitter data. Most of them are businesses which offer information about the engagement of followers with the content created. Their goal is to help increase the visibility of tweets for businesses and therefor the metrics are related to the followers and focus less on exploring content. 



This is also the solution offered by the Twitter analytics \todo{add link} some of the information it provides is the number of user that views your messages, how many new users are now following your account.
\newline
One such example is SproutSocial \todo{add link} which allow you to publish content from their application to Twitter, monitor your content for engagement and offer analytics on the users which interacted with your content.
\newline
Another example that tries to solve a similar problem to {\project} is TweetArchivist \todo{add link}. You are able to query specific time frames and see top users and words related to certain search terms, as well as the most shared URLs and the most influential \todo{explain how they are influential} users that have send messages.
\newline
\textbf{TweetMotif}\footnote{http://tweetmotif.com/about} retrieves tweets using the Twitter API based off of a user provided query. Then using n-grams extracts a certain number of topics and groups messages behind those topics, therefor giving an overview of what people are saying.

\subsection{3rd Party Clients}
\label{sub-sec:tpc}

There are a number of 3rd party clients. They allow for filtering of content based on a particular hashtag and popularity (this is rated by number of retweets and favorites). This is a good alternative for finding popular opinions, you can judge it by how popular that certain tweet is but it conveys either the voice of popular users which get lots of favorites and retweets or some tweets which happen to gain popularity by accident.

\subsection{Trends}
\label{sub-sec:trends}

Twitter website offers access to world-wide trends and also custom trends. First off world trends represents a list of key words present in tweets in a certain region. This allows you to browse all the tweets with those key words in real time. You do not have any other type of control over the data. The data is not grouped by any other means so exploring it means going through each tweet and reading it and taking into account the volume of tweets some trends may produce (as presented in the introduction of this chapter) this task may be impossible.

\section{Related Work}
\label{sub-sec:rel-work}

\textit{Politics, Twitter, and information discovery} by \textbf{Moritz Sudhof}. \footnote{http://web.stanford.edu/group/journal/cgi-bin/wordpress/wp-content/uploads/2012/09/Sudhof_Eng_2012.pdf}.
\newline
The aim of the paper is to cluster Twitter users into groups based on the opinions they expressed regarding a political controversy. The corpus is fixed and contains tweets from the time the events occurred, they have been selected due to using the same hashtag specific to the event.
\newline
Several different attempts are made at clustering the users using different methods. \textit{Tf-idf} and \textit{odds weighting} are used to extract relevant key words from messages. Multiple keywords shared between tweets are an indication of how similar they are and thus link the users together. \textit{Mentions}, referencing one or more users in your tweet, are also used. Mentioning someone in your tweet means that they are relevant to your opinion or somehow involved.
\newline
Finally \textit{hashtags} are taken into consideration the idea behind it being that users who send out messages using the same hashtags share similar opinions, again the more hashtags users share the similar they must be.

\textit{Topical Clustering of Tweets} by \textbf{Kevin Dela Rosa, Rushin Shah}. \footnote{http://www.cs.cmu.edu/~kdelaros/sigir-swsm-2011.pdf}
\newline
The scope of this paper is to classify Twitter messages into different categories. The authors consider hashtags an approximate indication of the message topic and use it to improve results. The topics categories in which the messages are sorted are predefined, and the corpus is fixed, composed of selected tweets that cover the predefined topics.
\newline
Before being able to cluster the messages they undergo an intermediate processing step. The processing step includes normalization in which several variations are experimented: tokenization, removal of rare terms, conversion to lowercase each in different combinations and results are tracked.
\newline
Both unsupervised and supervised methods are used. K-Means is used in combination with TF-IDF as a weight function for the unsupervised clustering. Rocchio classifier is used for the supervised clustering. Results are compared and it is noted that the supervised method has better results.

\textit{TweetMotif: Exploratory Search and Topic Summarization for Twitter} by \textbf{Brendan Oâ€™Connor, Michel Krieger, David Ahn} \footnote{http://brenocon.com/oconnor_krieger_ahn.icwsm2010.tweetmotif.pdf}
\newline
The paper presents the implementation details of TweetMotif. A platform that allows fetching tweets from Twitter Search API, generates 2-3 words topics from the newly formed corpus and associates messages to these topics.
\newline
The interface allows for a recursive drilldown into topics the goal being to offer a concise summary of the topics generated. Topic generation is achieved using n-grams with certain heuristics such as disregarding unigrams that are function words, or bigrams, trigrams that cross syntactic boundaries. Topics are merged and their sets of messages are combined. The user is presented with a limited number of topics to preserve cognitive load.

\textit{A survey of text clustering algorithms} by \textbf{Charu C. Aggarwal} and \textbf{ChengXiang Zhai} \footnote{http://www.charuaggarwal.net/text-cluster.pdf}
\newline
The paper discusses the problem of text clustering in a broader context, not only related to social networks. They present a very common problem that of misspellings or typographical errors in documents, a usual mistake in most online conversations. They advice on the removal of common terms that can skew results either using a list of stop words or using TF-IDF.
\newline
The paper is also concerned with the clustering of text streams. One of the methods they explore involves a weight function that rates newer documents better than older ones. So as time progresses old centroids might not prove relevant anymore and fade out. At the same time new centroids form up but not all might, this is why initially all new centroids start up as being treated as outliers.
\newline
In order to optimize and improve the quality of the clustering the paper introduces the method of \textit{semantic smoothing} meant to reduce the errors caused by semantic ambiguity. The method works by extracting phrases instead of single words from sentences therefor reducing the probability of a word meaning multiple things. For example the word \textit{star} might have different meanings but in the phrase \textit{fixed star} it most certainly refers to a celestial body.

\textit{A Web-based Kernel Function for Measuring the Similarity of Short Text Snippets} by \textbf{Mehran Sahami} and \textbf{Timothy D. Heilman} \footnote{http://wwwconference.org/www2006/programme/files/pdf/3069.pdf}
\newline
\newline
The paper handles the issue of measuring similarity for really short sentences such as search queries which might not have any terms in common so techniques such as cosine similarity do nothing to help. The proposed solution in the paper is to use each term in the queries we are trying to match up as web search terms. Each term is used to query the web for documents and therefor provide context on it, these are called \textit{context vectors}. Therefor even though the terms \textit{AI} and \textit{Artificial Intelligence} would yield a cosine of 0, and therefor no similarity gathering a number of documents on the terms would help improve the context and compute a much better similarity for the two.
\newline
The main objective of the technique and the objective of the paper is finding ways to improve search suggestions to Google users.