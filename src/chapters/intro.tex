\chapter{Introduction}
\label{chapter:intro}

Social media platforms are no longer an emerging field, they have become well established and millions of messages are exchanged daily by people globally. A variety of application clients and services try to keep up with this surge of information by offering users information about popular topics or highlights about the events that are happening around them. They are promoting popular content, either by number of clicks, views, favorites or other metrics, and although this is effective for controversial topics, it does little to highlight other subjects of conversation.
\newline
\newline
In this paper, we present a study on the clustering of messages from the Twitter platform, also known as \textit{tweets}, inspired by the website's \textit{Trends}category  which presents the most popular subjects either worldwide or in a certain geographical region. The aim of our paper is to explore more than just popular subjects by just providing a query by which to extract conversations and cluster the resulting discussions based on keywords, frequencies, weights and part of speech tagging. The purpose of the clustering is to offer an in depth view of the different conversation taking place on the same topic either trending or not and to be able to gain a high level overview of the conversations taking place around a certain subject.
\newline
\newline
It is no longer possible to track individual messages when hundreds of them per second are coming in. By clustering similar conversations together and offering an interface through which to explore the information, it is possible to view multiple opinions on the same subject in a structured way and get more information than just having everything in one place.
\newline
\newline
The process through which the clustering is achieved is separated into three parts: data collection via the Twitter public API, message annotation with part-of-speech tags and message clustering. The messages provided by the website's API already provide a filtering option, you can specify keywords that you want to be part of the messages you get back. This might provide some indication of the conversation topic but getting an overview of the different conversations on the same subject is not a trivial task because messages have no obvious order. Another concern related to online conversations is the amount of syntactic errors due to the fast paced way they usually take place or due to the restrictions imposed by Twitter (the character limit inside of messages).
\newline
\newline
We will provide more information about the problems encountered and the solutions we implemented in the following sections.

\section{Project Description}
\label{sec:proj}

This first sections of the paper will discuss project scope and what objectives we have set to accomplish. Afterwards we will discuss related work in the field, implemented solutions that deal with Twitter conversations or papers written on this subject. The popularity of the platform, the large quantity of messages and the fact that it is relatively easy to have access to large corpuses of text from different websites have made Twitter conversations a popular topic of research. We then continue by giving a detailed explanation of the clustering process the algorithm chosen, how does K-Means work, and the weight function, cosine similarity which is part of the algorithm. The Implementation details section provides a look into the system architecture, some of the trade-offs made and the benefits, and continues with parsing and message aggregation. The next section will go into details regarding testing and the results obtained and the last part will offer suggestions for further improvements and research.

\subsection{Project Scope}
\label{sub-sec:proj-scope}

We will first offer a broader explanation of the problem we wish to solve.
\newline
Twitter\footnote{https://support.twitter.com/articles/49309-using-hashtags-on-twitter} is an online micro blogging platform and social networking website. Users communicate through short 140 character messages called \"tweets\". To ease communication people use \"mentions\", the \"@\" character followed by a persons name. This is a way to involve another account into the conversation. Another feature of the conversation is the \"hashtag\", the \"\#\" sign followed by a word this is used to highlight key parts in the message, either a feeling or subject. Popular such hashtags are included in the Trending Topics. These are popular subjects automatically generated from conversations taking place worldwide or in a certain region. This is why people often times include hashtags in order to associate their message with a popular topic. Users can also favorite a tweet, and "retweet" it, meaning they share it with the people that follow them while still attributing the message to the original author. These two metrics contribute to the overall popularity of a tweet.
\newline
\newline
Twitter is an interesting platform for research because of the large number of messages exchanged daily. There are 500 million tweets sent daily by its 302 million monthly active users\footnote{https://about.twitter.com/company} with a record of 143,199 tweets per second\footnote{https://blog.twitter.com/2013/new-tweets-per-second-record-and-how}. People usually turn to Twitter during major natural events, sporting events, award ceremonies and so on. With such a high amount of information coming in every second it is almost impossible to keep track of everything that is discussed.
\newline
\newline
The "Trends" category highlights all popular topics and hashtags but exploring any one topic reveals a very large number of messages with just as more coming in every second (for popular subjects). This makes it very hard to see different points of view, different opinions on the matter. The aim of {\project}  is to offer a high level overview of the conversation, where different opinions on the same topic are grouped into different clusters. This would make it easy to identify what kind of messages you are likely to find in a cluster just by reading some of them and would allow quick understand all aspects of a developing story.
\newline
\newline
Consider the following scenario: during a global sporting event such as the football world cup which takes place over the course of several week, you want to keep track of the public opinion for your country's national team. If they are playing a game it's most likely that they are trending and a hashtag has already become popular between the people exchanging messages about the game. But how do you track the information? What if the hashtag includes both team (for example \#GERvsBRA used to track Germany - Brazil game) what if you want to see information about the first goal, or a certain player in the game. Clustering all available messages would easily reveal the ones referring to one of the teams or an individual player. This is where {\project}  will in and change the way information is being discovered.
\newline
\newline
Twitter has a powerful web platform and that is why we want to take advantage of this by allowing our project to interact with the web portal. As we present the clusters and associated messages it should be accessible to navigate between our interface and Twitter. This would allow access to the profile of the users who sent out the messages. It would give direct link to the message and therefor the context of the message would be available.

The scope of the project \textbf{\project} is to provide close to realtime 
clustering of conversations that take place in the online medium. My choice for
a social network is Twitter. Twitter has around 302 million active users (May 2015)
\footnote{\url{https://about.twitter.com/company}} who send 500 million tweets
each day mostly from their mobile phones. A tweet is a 140 character long message
and because of this conversations are hard to keep track of and provide little to
no context on their subject. This makes them an excellent candidate for a clustering application like \textbf{\project} which aims to provide an overview for  
conversations spanning over all the topics the user of the application provided.

\subsection{Project Objectives}
\label{sub-sec:proj-objectives}

With \textbf{\project} we want to provide close to realtime 
clustering of conversations that take place on the Twitter social social platform. As a result of its popularity the platform is generating massive amounts of messages that make it increasingly difficult to go through and read the content. We are trying to answer several questions: is it possible to manage a large number of online conversations on a particular subject, can you easily  identify the different points of view expressed, can you identify the different opinions expressed by the users of the platform.
\newline
\newline
Having answers to these questions we can easily monitor news reports, popular social events and track people's feelings about current events. It is also a test for the current technology stack available, Twitter employs hundreds of engineers to handle its infrastructure and services, we want to see if it is possible to build a system capable of scaling and handling a fraction of the traffic generated by the platform just by using open source libraries for our solution.
\newline
\newline
We want to achieve a solution that is easy to deploy and set up, that is able to connect and retrieve real time messages and that can group messages together with certain accuracy based on their topic.
\newline
To achieve this objective there are several components that go into the architecture:
\begin{itemize}
	\item Data collection --- This step involves connecting and retrieving public messages from the Twitter platform matching a particular query of interest. This is achieved via Twitter's streaming API which serves a percentage amount of all conversations. The system requires that all requests be done by authenticated clients. After registering with the service it automatically starts sending realtime messages that match your search terms. Due to the difference between the rate of processing and the rate at which messages are coming in a temporary data storage is required.
	\item Message parsing --- The tweets that have been acquired need to be parsed. By parsing we are referring to an initial processing step in which meta information is added to messages before they can enter the clustering algorithm. Due to the short nature of the messages, 10-14 words on average, the information is filled with jargon or syntactic errors in an attempt to increase the amount of information in such a small payload. In this step each word is augmented with its corresponding part of speech tag and its contribution to the overall document is computed. The importance of terms is the result of TF-IDF, a computational step in which word frequency is used to attribute a weight to each of them.
	\item Message clustering --- The result of this step will be a mapping of message ids to clusters. By cluster we are referring to a group of messages that all concern the same topic. The new messages obtained as a result of the previous step are clustered using K-Means algorithm. The algorithm requires a weight function, for this we have chosen the cosine similarity function. The algorithm works in steps, each step is an attempt to improve the overall score of a cluster (how precise is the grouping we have created). This can be quantified using the weight function we previously mentioned. This works by normalizing all the messages, a bucket is created which contains the sum of all words in all documents  and each sentence is transformed into a vector who's elements specify if a certain word form the bucket is present or not.
	\item Cluster API --- The mapping from the previous step is transformed into actual clusters of messages now that we now how to assign them together. The backend exposes the clusters of messages via an HTTP enpoint. Any number of clients can connect and have access to the information. The endpoint serves the messages in JSON format, a popular solution of web applications. This makes it easy and accessible for any number of applications to connect and consume the available data without the server having any prior knowledge of the clients it serves.
	\item Frontend --- An application that runs in the browser and connects to the endpoint described in the previous step. Using the canvas API it draws messages that belong to the same clusters closer to each other making it easy to identify them. It also displays the full message and user and allows you to explore the different clusters. This is also an easy way to verify some of our assumptions: we can expand the clusters and assert that the messages have been grouped with certain precision. The interface also links back to the author and original message making it easy to get more context or explore a certain users timeline.
\end{itemize}
This was meant to provide a high level overview of the system. We will go into further details in the Design and Implementation categories.

\subsection{Related Work}

There are many services and applications that are in some way dependent of Twitter data, whether they just simply archive information so that they may sell large corpuses of data, or actually parse and analyze public user streams and send out alerts or reports regarding search terms or mentions.
\newline
At the same time a lot of academic papers are concerned with the content of Twitter conversations. Topics such as summarization of Twitter trends, efficient searching of content, tracking user sentiment and clustering are still open for discussion.
\newline
We will delve into further details in the Related Work section and comment on some of these applications as well as the academic papers.